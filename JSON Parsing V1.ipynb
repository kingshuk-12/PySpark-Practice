{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9446e9c-f0d7-43d5-b4c1-38fd9d721399",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate a sample XML file in DBFS location\n",
    "sample_json_content = \"\"\"{\n",
    "  \"bank\": {\n",
    "    \"id\": \"B001\",\n",
    "    \"name\": \"Global Commercial Bank\",\n",
    "    \"branches\": [\n",
    "      {\n",
    "        \"id\": \"BR001\",\n",
    "        \"location\": {\n",
    "          \"city\": \"Mumbai\",\n",
    "          \"state\": \"Maharashtra\",\n",
    "          \"country\": \"India\"\n",
    "        },\n",
    "        \"employees\": [\n",
    "          {\n",
    "            \"id\": \"E1001\",\n",
    "            \"name\": {\n",
    "              \"first\": \"Rajesh\",\n",
    "              \"last\": \"Mehta\"\n",
    "            },\n",
    "            \"role\": \"Relationship Manager\",\n",
    "            \"clients_assigned\": [\"CUST001\", \"CUST002\"]\n",
    "          },\n",
    "          {\n",
    "            \"id\": \"E1002\",\n",
    "            \"name\": {\n",
    "              \"first\": \"Anita\",\n",
    "              \"last\": \"Sharma\"\n",
    "            },\n",
    "            \"role\": \"Credit Analyst\",\n",
    "            \"clients_assigned\": [\"CUST003\"]\n",
    "          }\n",
    "        ],\n",
    "        \"customers\": [\n",
    "          {\n",
    "            \"id\": \"CUST001\",\n",
    "            \"name\": {\n",
    "              \"first\": \"Amit\",\n",
    "              \"last\": \"Patel\"\n",
    "            },\n",
    "            \"contact\": {\n",
    "              \"email\": \"amit.patel@example.com\",\n",
    "              \"phones\": [\n",
    "                {\"type\": \"mobile\", \"number\": \"+91-9876543210\"},\n",
    "                {\"type\": \"home\", \"number\": \"+91-2267890123\"}\n",
    "              ]\n",
    "            },\n",
    "            \"accounts\": [\n",
    "              {\n",
    "                \"id\": \"ACC001\",\n",
    "                \"type\": \"Checking\",\n",
    "                \"balance\": 150000.50,\n",
    "                \"currency\": \"INR\",\n",
    "                \"transactions\": [\n",
    "                  {\n",
    "                    \"id\": \"TXN001\",\n",
    "                    \"date\": \"2025-08-01\",\n",
    "                    \"amount\": -5000,\n",
    "                    \"merchant\": {\n",
    "                      \"name\": \"Reliance Retail\",\n",
    "                      \"category\": \"Shopping\"\n",
    "                    },\n",
    "                    \"channel\": \"Debit Card\",\n",
    "                    \"tags\": [\"shopping\", \"debit\"]\n",
    "                  },\n",
    "                  {\n",
    "                    \"id\": \"TXN002\",\n",
    "                    \"date\": \"2025-08-03\",\n",
    "                    \"amount\": 20000,\n",
    "                    \"merchant\": {\n",
    "                      \"name\": \"NEFT Transfer\",\n",
    "                      \"category\": \"Transfer\"\n",
    "                    },\n",
    "                    \"channel\": \"Online Banking\",\n",
    "                    \"tags\": [\"salary\", \"credit\"]\n",
    "                  }\n",
    "                ]\n",
    "              },\n",
    "              {\n",
    "                \"account_id\": \"ACC002\",\n",
    "                \"type\": \"Savings\",\n",
    "                \"balance\": 350000.75,\n",
    "                \"currency\": \"INR\",\n",
    "                \"transactions\": []\n",
    "              }\n",
    "            ],\n",
    "            \"loans\": [\n",
    "              {\n",
    "                \"id\": \"LN001\",\n",
    "                \"type\": \"Home Loan\",\n",
    "                \"principal\": 5000000,\n",
    "                \"interest_rate\": 7.5,\n",
    "                \"tenure_months\": 240,\n",
    "                \"repayments\": [\n",
    "                  {\n",
    "                    \"installment_no\": 1,\n",
    "                    \"date\": \"2025-09-01\",\n",
    "                    \"amount_due\": 48250.75,\n",
    "                    \"status\": \"Pending\"\n",
    "                  }\n",
    "                ]\n",
    "              }\n",
    "            ],\n",
    "            \"credit_cards\": [\n",
    "              {\n",
    "                \"id\": \"CC001\",\n",
    "                \"card_type\": \"VISA Platinum\",\n",
    "                \"limit\": 200000,\n",
    "                \"current_due\": 15300,\n",
    "                \"transactions\": [\n",
    "                  {\n",
    "                    \"txn_id\": \"CCTXN001\",\n",
    "                    \"date\": \"2025-07-25\",\n",
    "                    \"merchant\": {\n",
    "                      \"name\": \"Indigo Airlines\",\n",
    "                      \"category\": \"Travel\"\n",
    "                    },\n",
    "                    \"amount\": 12500,\n",
    "                    \"currency\": \"INR\",\n",
    "                    \"status\": \"Posted\"\n",
    "                  }\n",
    "                ]\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "dbutils.fs.put(\"/Volumes/workspace/default/test/sample.json\", sample_json_content, overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a18461e7-fbd0-4a8a-92cf-35d571f52be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the Json file using Spark with option set before .json()\n",
    "df = spark.read.option(\n",
    "    \"inferSchema\",\n",
    "    \"false\"\n",
    ").option(\"multiline\", \"true\").json(\n",
    "    \"/Volumes/workspace/default/test/sample.json\"\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "833c80b2-b57b-473d-91ca-7f8561cc2eb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "\n",
    "def flatten_df(df: DataFrame, col_to_drop: list = None) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Recursively flattens all StructType and ArrayType columns in a DataFrame.\n",
    "    Drops specified columns early to avoid duplication.\n",
    "    \"\"\"\n",
    "    if col_to_drop:\n",
    "        # Drop at the very start\n",
    "        df = df.drop(*col_to_drop)\n",
    "\n",
    "    complex_fields = True\n",
    "    while complex_fields:\n",
    "        complex_fields = False\n",
    "        flat_cols = []\n",
    "\n",
    "        for field in df.schema.fields:\n",
    "            col_name = field.name\n",
    "            dtype = field.dataType\n",
    "\n",
    "            if isinstance(dtype, T.StructType):\n",
    "                complex_fields = True\n",
    "                for subfield in dtype.fields:\n",
    "                    flat_cols.append(\n",
    "                        F.col(f\"{col_name}.{subfield.name}\")\n",
    "                        .alias(f\"{col_name}_{subfield.name}\")\n",
    "                    )\n",
    "            elif isinstance(dtype, T.ArrayType):\n",
    "                complex_fields = True\n",
    "                # explode array â†’ keep nulls with explode_outer\n",
    "                df = df.withColumn(col_name, F.explode_outer(F.col(col_name)))\n",
    "                flat_cols.append(F.col(col_name))\n",
    "            else:\n",
    "                flat_cols.append(F.col(col_name))\n",
    "\n",
    "        df = df.select(flat_cols)\n",
    "\n",
    "        # Drop again if needed in subsequent iterations\n",
    "        if col_to_drop:\n",
    "            df = df.drop(*col_to_drop)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7990a487-7e0e-4f3a-8607-85a6b9d0ffd3",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756029238962}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      },
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1757767847439}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import contextvars\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "shred_points = [(\"bank.branches\", \"array\")]  # This is a manual step\n",
    "col_to_drop = [\"branches_employees\"]  # manual\n",
    "\n",
    "def process_shred_point(i):\n",
    "    \"\"\"\n",
    "    Processes a shred point by selecting the specified nested array column and its parent id columns,\n",
    "    then flattens the resulting DataFrame using the flatten_df function.\n",
    "\n",
    "    Args:\n",
    "        i (tuple): A tuple containing the column path and its type.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the original selected DataFrame and its flattened version.\n",
    "    \"\"\"\n",
    "    parent_tags = i[0].split(\".\")\n",
    "    result = []\n",
    "    for j in range(1, len(parent_tags)):\n",
    "        result.append(\".\".join(parent_tags[:j]) + \".id\")\n",
    "    df_local = df.select(col(i[0]), *[col(c).alias(c.replace(\".\", \"_\")) for c in result])\n",
    "    flattened_df_local = flatten_df(df_local, col_to_drop)\n",
    "    return df_local, flattened_df_local\n",
    "\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    futures = []\n",
    "    for i in shred_points:\n",
    "        ctx = contextvars.copy_context() # copied from Databricks AI, can be avoided\n",
    "        futures.append(executor.submit(ctx.run, process_shred_point, i))\n",
    "    for future in as_completed(futures):\n",
    "        df_local, flattened_df_local = future.result()\n",
    "        display(df_local)\n",
    "        display(flattened_df_local)\n",
    "        flattened_df_local.write.mode(\"append\").option(\"mergeSchema\",\"true\").saveAsTable(\"default.flattened_df_local\")\n",
    "        results.append(flattened_df_local)\n",
    "display(flattened_df_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02b80023-d794-42ea-8d83-f8f1680eacf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "JSON Parsing V1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
